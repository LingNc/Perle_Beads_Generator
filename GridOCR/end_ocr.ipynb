{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7782f757",
   "metadata": {},
   "source": [
    "# 第1步：导入库和加载图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2102023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['Noto Sans CJK SC', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 加载图像\n",
    "img = cv2.imread(\"table_sample.jpg\")  # 替换为你的图片路径\n",
    "if img is None:\n",
    "    raise ValueError(\"无法加载图像，请检查文件路径。\")\n",
    "\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(8,6),dpi=300)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('原始拼豆图纸')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"图像尺寸: {img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ce376",
   "metadata": {},
   "source": [
    "# 第2步：多通道梯度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel 算子 检测水平和竖直的边缘\n",
    "def get_gradient_sobel(channel:cv2.Mat,ksize:int) -> np.ndarray:\n",
    "    grad_x = cv2.Sobel(channel, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    grad_y = cv2.Sobel(channel, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    return np.sqrt(grad_x**2 + grad_y**2)\n",
    "\n",
    "# Scharr 算子\n",
    "def get_gradient_scharr(channel: cv2.Mat) -> np.ndarray:\n",
    "    grad_x = cv2.Scharr(channel, cv2.CV_64F, 1, 0)\n",
    "    grad_y = cv2.Scharr(channel, cv2.CV_64F, 0, 1)\n",
    "    return np.sqrt(grad_x**2 + grad_y**2)\n",
    "\n",
    "# Laplacian 算子\n",
    "def get_gradient_laplacian(channel: cv2.Mat,ksize: int) -> np.ndarray:\n",
    "    laplacian = cv2.Laplacian(channel, cv2.CV_64F,ksize=ksize)\n",
    "    return np.abs(laplacian)\n",
    "\n",
    "def get_gradient(channel) -> np.ndarray:\n",
    "    return get_gradient_scharr(channel=channel)  # 使用Canny边缘检测\n",
    "\n",
    "# RGB三通道分别计算\n",
    "b, g, r = cv2.split(img)\n",
    "grad_r = get_gradient(r)\n",
    "grad_g = get_gradient(g)\n",
    "grad_b = get_gradient(b)\n",
    "\n",
    "# LAB色差通道\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "l, a, b_lab = cv2.split(lab)\n",
    "grad_a = get_gradient(a)  # 红绿色差\n",
    "grad_b_lab = get_gradient(b_lab)  # 黄蓝色差\n",
    "\n",
    "# 可视化各通道梯度\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8), dpi=300)\n",
    "axes[0,0].imshow(grad_r, cmap='hot'), axes[0,0].set_title('R通道梯度'), axes[0,0].axis('off')\n",
    "axes[0,1].imshow(grad_g, cmap='hot'), axes[0,1].set_title('G通道梯度'), axes[0,1].axis('off')\n",
    "axes[0,2].imshow(grad_b, cmap='hot'), axes[0,2].set_title('B通道梯度'), axes[0,2].axis('off')\n",
    "axes[1,0].imshow(grad_a, cmap='hot'), axes[1,0].set_title('A通道梯度(红绿色差)'), axes[1,0].axis('off')\n",
    "axes[1,1].imshow(grad_b_lab, cmap='hot'), axes[1,1].set_title('B通道梯度(黄蓝色差)'), axes[1,1].axis('off')\n",
    "axes[1,2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41281c0",
   "metadata": {},
   "source": [
    "# 第3步：智能权重融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748dda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个通道的平均强度作为权重\n",
    "weights = {\n",
    "    'r': np.mean(grad_r),\n",
    "    'g': np.mean(grad_g),\n",
    "    'b': np.mean(grad_b),\n",
    "    'a': np.mean(grad_a),\n",
    "    'b_lab': np.mean(grad_b_lab)\n",
    "}\n",
    "\n",
    "print(\"各通道平均梯度强度:\")\n",
    "for k, v in weights.items():\n",
    "    print(f\"{k}: {v:.2f}\")\n",
    "\n",
    "# 归一化并融合\n",
    "total_weight = sum(weights.values())\n",
    "fused_gradient = (\n",
    "    (weights['r']/total_weight) * grad_r +\n",
    "    (weights['g']/total_weight) * grad_g +\n",
    "    (weights['b']/total_weight) * grad_b\n",
    "\n",
    "    # + (weights['a']/total_weight) * grad_a * 1.5 +    # 色差通道加权\n",
    "    # (weights['b_lab']/total_weight) * grad_b_lab * 1.5\n",
    ")\n",
    "\n",
    "# 对融合图像进行高斯滤波\n",
    "# fused_gradient = cv2.GaussianBlur(fused_gradient.astype(np.float32), (5, 5), 0)\n",
    "# fused_gradient = cv2.bilateralFilter(fused_gradient.astype(np.float32), d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "# 使用60%阈值的二值图进行线检测\n",
    "threshold_55 = fused_gradient > np.percentile(fused_gradient, 60)\n",
    "binary_55 = (threshold_55 * 255).astype(np.uint8)\n",
    "binary_55 = cv2.GaussianBlur(binary_55.astype(np.float32), (5, 5), 0)\n",
    "binary_55 = binary_55 > np.percentile(binary_55, 60)\n",
    "binary_55 = (binary_55 * 255).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(12, 4),dpi=300)\n",
    "plt.subplot(131), plt.imshow(grad_r, cmap='hot'), plt.title('单通道(R)'), plt.axis('off')\n",
    "plt.subplot(132), plt.imshow(fused_gradient, cmap='hot'), plt.title('多通道融合'), plt.axis('off')\n",
    "plt.subplot(133), plt.imshow(binary_55, cmap='gray'), plt.title('60%阈值预览'), plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac14967",
   "metadata": {},
   "source": [
    "## 生成文字掩膜（单词分布概率图）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ecf0f",
   "metadata": {},
   "source": [
    "### 导入需要的库并环境检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# === 环境检测：CUDA 与 ONNXRuntime ===\n",
    "print(\"=== 环境检测 ===\")\n",
    "# 检查 onnxruntime GPU provider\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    print(\"ONNXRuntime 可用提供者:\", ort.get_available_providers())\n",
    "except ImportError:\n",
    "    print(\"未安装 onnxruntime\")\n",
    "print(\"================\")\n",
    "\n",
    "import onnxruntime as ort\n",
    "\n",
    "def inspect_onnx_model(onnx_path:str,use_gpu:bool) -> ort.InferenceSession | None:\n",
    "    \"\"\"检查 ONNX 模型的输入输出信息\"\"\"\n",
    "    try:\n",
    "        providers = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"] if use_gpu else [\"CPUExecutionProvider\"]\n",
    "        if use_gpu is True:\n",
    "            print(\"使用 GPU 加速，提供者:\", providers)\n",
    "        else:\n",
    "            print(\"使用 CPU 运行，提供者:\", providers)\n",
    "        session = ort.InferenceSession(onnx_path, providers=providers)\n",
    "\n",
    "        print(f\"\\n=== 模型信息：{onnx_path} ===\")\n",
    "\n",
    "        # 输入信息\n",
    "        for i, input_info in enumerate(session.get_inputs()):\n",
    "            print(f\"输入 {i}:\")\n",
    "            print(f\"  名称: {input_info.name}\")\n",
    "            print(f\"  形状: {input_info.shape}\")\n",
    "            print(f\"  类型: {input_info.type}\")\n",
    "\n",
    "            # 检查是否有动态维度\n",
    "            if any(isinstance(dim, str) or dim == -1 for dim in input_info.shape):\n",
    "                print(f\"  ✓ 支持动态尺寸\")\n",
    "            else:\n",
    "                print(f\"  ⚠️ 固定尺寸，必须严格匹配\")\n",
    "\n",
    "        # 输出信息\n",
    "        for i, output_info in enumerate(session.get_outputs()):\n",
    "            print(f\"输出 {i}:\")\n",
    "            print(f\"  名称: {output_info.name}\")\n",
    "            print(f\"  形状: {output_info.shape}\")\n",
    "            print(f\"  类型: {output_info.type}\")\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "        return session\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 无法检查模型信息: {e}\")\n",
    "        return None\n",
    "\n",
    "# 文件路径\n",
    "onnx_path = \"Text-Remove-Model/ch_PP-OCRv5_server_det.onnx\"\n",
    "# 图片路径\n",
    "img_path = \"table_sample.jpg\"\n",
    "# 使用GPU\n",
    "use_gpu = True\n",
    "\n",
    "# 首先检查模型的输入要求\n",
    "session = inspect_onnx_model(onnx_path,use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e4538",
   "metadata": {},
   "source": [
    "### 自动处理图片分辨率和模型对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2be843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入图片\n",
    "img = cv2.imread(img_path)\n",
    "if img is None:\n",
    "    print(f\"无法读取图像，{img_path}\")\n",
    "\n",
    "# 获取模型输入形状\n",
    "model_input_shape = session.get_inputs()[0].shape\n",
    "\n",
    "# 智能推断输入尺寸\n",
    "target_size = \"auto\"  # 默认自动\n",
    "\n",
    "# 最优先：从模型本身获取固定尺寸\n",
    "if model_input_shape and len(model_input_shape) >= 4:\n",
    "    # 检查是否是固定尺寸 (非动态维度)\n",
    "    h_dim, w_dim = model_input_shape[2], model_input_shape[3]\n",
    "    if isinstance(h_dim, int) and isinstance(w_dim, int) and h_dim == w_dim:\n",
    "        target_size = h_dim\n",
    "        print(f\"从模型获取固定输入尺寸: {target_size}x{target_size}\")\n",
    "\n",
    "# 次优先：从文件名推断\n",
    "if target_size == \"auto\":\n",
    "    # 使用正则表达式从文件名中提取尺寸信息\n",
    "    size_pattern = r'(\\d+)x\\1'  # 匹配如 1024x1024, 2400x2400 等格式\n",
    "    size_match = re.search(size_pattern, onnx_path)\n",
    "\n",
    "    if size_match:\n",
    "        target_size = int(size_match.group(1))\n",
    "        print(f\"从文件名检测到固定尺寸: {target_size}x{target_size}\")\n",
    "    else:\n",
    "        # 如果没有找到标准格式，尝试匹配 NxN 格式（如 600x600, 800x800 等）\n",
    "        general_size_pattern = r'(\\d+)x(\\d+)'  # 匹配任意 NxM 格式\n",
    "        general_match = re.search(general_size_pattern, onnx_path)\n",
    "        if general_match:\n",
    "            width, height = int(general_match.group(1)), int(general_match.group(2))\n",
    "            if width == height:  # 只接受正方形输入\n",
    "                target_size = width\n",
    "                print(f\"从文件名推断尺寸: {target_size}x{target_size}\")\n",
    "            else:\n",
    "                print(f\"从文件名检测到非正方形尺寸 {width}x{height}，将使用 {max(width, height)}x{max(width, height)}\")\n",
    "                target_size = max(width, height)\n",
    "\n",
    "    # 对于从文件名中获取的尺寸，也确保是32的倍数\n",
    "    if isinstance(target_size, int):\n",
    "        original_size = target_size\n",
    "        target_size = ((target_size + 31) // 32) * 32\n",
    "        if original_size != target_size:\n",
    "            print(f\"输入尺寸从 {original_size} 调整为 {target_size} (32的倍数)\")\n",
    "\n",
    "# 如果没有从文件名中找到尺寸，读取图像来自动判断到最近的一个32倍\n",
    "if target_size == \"auto\":\n",
    "    temp_img = img\n",
    "    if temp_img is not None:\n",
    "        h, w = temp_img.shape[:2]\n",
    "        max_dim = max(h, w)\n",
    "\n",
    "        # 最大限制 4096\n",
    "        target_size = min(4096,max_dim)\n",
    "\n",
    "        # 确保是32的倍数\n",
    "        target_size = ((target_size + 31) // 32) * 32\n",
    "        print(f\"图像尺寸: {w}x{h}, 自动选择模型输入尺寸: {target_size}x{target_size}\")\n",
    "    else:\n",
    "        target_size = 1024  # 默认值\n",
    "\n",
    "print(f\"加载模型: {onnx_path}\")\n",
    "print(f\"处理图像: {img_path}\")\n",
    "print(f\"使用输入尺寸: {target_size}x{target_size}\")\n",
    "# print(f\"推理引擎: {'ONNXRuntime' if use_ort else 'OpenCV DNN'}\")\n",
    "print(f\"GPU加速: {'开启' if use_gpu else '关闭'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66e633",
   "metadata": {},
   "source": [
    "### 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc007a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img: np.ndarray,target_size:int = 1024) -> tuple[np.ndarray, float, tuple[int, int]]:\n",
    "    \"\"\"预处理方式 - 保持原始比例并缩放到对应的大小画布上\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # 计算缩放比例，保持长宽比\n",
    "    scale = target_size / max(h, w)\n",
    "    new_h, new_w = int(h * scale), int(w * scale)\n",
    "\n",
    "    # resize图像\n",
    "    img_resized = cv2.resize(img, (new_w, new_h))\n",
    "\n",
    "    # 创建目标尺寸的画布（填充黑色）\n",
    "    canvas = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
    "\n",
    "    # 将resize后的图像放到画布中央\n",
    "    start_h = (target_size - new_h) // 2\n",
    "    start_w = (target_size - new_w) // 2\n",
    "    canvas[start_h:start_h+new_h, start_w:start_w+new_w] = img_resized\n",
    "\n",
    "    return canvas, scale, (start_w, start_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728d162",
   "metadata": {},
   "source": [
    "### 将概率图缩放回原图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_original_prob_map(\n",
    "        prob_map:np.ndarray,\n",
    "        scale:float,\n",
    "        offset:tuple[int,int],\n",
    "        original_size:tuple[int,int],\n",
    "        target_size:int\n",
    "        ):\n",
    "    \"\"\"将概率图缩放回原图尺寸\"\"\"\n",
    "    original_w, original_h = original_size\n",
    "    start_w, start_h = offset\n",
    "\n",
    "    # 计算原图在预处理图像中的有效区域尺寸\n",
    "    scaled_w = int(original_w * scale)\n",
    "    scaled_h = int(original_h * scale)\n",
    "\n",
    "    # 从概率图中提取有效区域（去除padding）\n",
    "    end_h = min(start_h + scaled_h, target_size)\n",
    "    end_w = min(start_w + scaled_w, target_size)\n",
    "\n",
    "    # 提取有效区域\n",
    "    valid_prob = prob_map[start_h:end_h, start_w:end_w]\n",
    "\n",
    "    # 缩放回原图尺寸\n",
    "    if valid_prob.size > 0:\n",
    "        prob_resized = cv2.resize(valid_prob, (original_w, original_h))\n",
    "        # 归一化到0-255用于保存\n",
    "        prob_normalized = (prob_resized * 255).astype(np.uint8)\n",
    "        return prob_normalized\n",
    "    else:\n",
    "        return np.zeros((original_h, original_w), dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab7da3",
   "metadata": {},
   "source": [
    "### 文本检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84465c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_word(\n",
    "        onnx_session:ort.InferenceSession,\n",
    "        img:np.ndarray,\n",
    "        target_size:int=1024,\n",
    "        threshold:float=0.3,\n",
    "        use_gpu:bool=False):\n",
    "    \"文件检测函数\"\n",
    "    # 获取原始图像尺寸\n",
    "    original_h, original_w = img.shape[:2]\n",
    "    print(f\"原始图像尺寸: {original_w}x{original_h}\")\n",
    "\n",
    "    # 预处理\n",
    "    processed_img, scale, offset = preprocess_image(img, target_size)\n",
    "    print(f\"预处理后尺寸: {processed_img.shape}\")\n",
    "    print(f\"缩放比例: {scale:.4f}, 偏移: {offset}\")\n",
    "\n",
    "    # 检查模型要求的通道数\n",
    "    model_input_shape = onnx_session.get_inputs()[0].shape\n",
    "    if len(model_input_shape) >= 2 and isinstance(model_input_shape[1], int):\n",
    "        expected_channels = model_input_shape[1]\n",
    "        print(f\"模型期望输入通道数: {expected_channels}\")\n",
    "    else:\n",
    "        expected_channels = 3  # 默认RGB三通道\n",
    "\n",
    "    # 创建blob\n",
    "    if expected_channels == 1:\n",
    "        # 单通道模型：转换为灰度图\n",
    "        gray_img = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)\n",
    "        blob = cv2.dnn.blobFromImage(gray_img,\n",
    "                                    scalefactor=1.0/255.0,\n",
    "                                    size=(target_size, target_size),\n",
    "                                    mean=(0.485,),  # 单通道均值\n",
    "                                    swapRB=False,\n",
    "                                    crop=False)\n",
    "        print(f\"单通道模型，使用灰度图输入\")\n",
    "    else:\n",
    "        # 多通道模型：RGB\n",
    "        blob = cv2.dnn.blobFromImage(processed_img,\n",
    "                                    scalefactor=1.0/255.0,\n",
    "                                    size=(target_size, target_size),\n",
    "                                    mean=(0.485, 0.456, 0.406),  # ImageNet均值\n",
    "                                    swapRB=True,  # BGR->RGB\n",
    "                                    crop=False)\n",
    "        print(f\"多通道模型，使用RGB输入\")\n",
    "\n",
    "    print(f\"输入 blob 形状: {blob.shape}\")\n",
    "\n",
    "    # 使用 ONNXRuntime 进行推理\n",
    "    print(f\"使用 ONNXRuntime 进行推理...\")\n",
    "    try:\n",
    "        input_name = onnx_session.get_inputs()[0].name\n",
    "        outputs = onnx_session.run(None, {input_name: blob.astype(np.float32)})\n",
    "        print(f\"推理成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"推理失败: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"模型输出数量: {len(outputs)}\")\n",
    "    for i, output in enumerate(outputs):\n",
    "        print(f\"输出 {i} 形状: {output.shape}, 数值范围: [{np.min(output):.4f}, {np.max(output):.4f}]\")\n",
    "\n",
    "    # 处理输出（通常是概率图）\n",
    "    if len(outputs) == 0:\n",
    "        return None\n",
    "\n",
    "    # 取第一个输出作为概率图\n",
    "    prob_map = outputs[0]\n",
    "\n",
    "    # 处理不同的输出格式\n",
    "    if len(prob_map.shape) == 4:  # [N, C, H, W]\n",
    "        prob_map = prob_map[0, 0]  # 取第一个batch和channel\n",
    "    elif len(prob_map.shape) == 3:  # [N, H, W]\n",
    "        prob_map = prob_map[0]\n",
    "\n",
    "    print(f\"概率图形状: {prob_map.shape}\")\n",
    "\n",
    "    # 调整到预处理图像尺寸\n",
    "    if prob_map.shape != (target_size, target_size):\n",
    "        prob_map = cv2.resize(prob_map, (target_size, target_size))\n",
    "\n",
    "    # 正确生成原图尺寸的概率图\n",
    "    prob_original = generate_original_prob_map(prob_map,scale,offset,(original_w,original_h),target_size)\n",
    "\n",
    "    return prob_original\n",
    "\n",
    "# 对推理得图像文字概率图\n",
    "prob_map = detect_word(onnx_session=session, img=img, target_size=target_size, use_gpu=use_gpu)\n",
    "# 根据概率图提取边缘并附加在原图上，使用绿色\n",
    "if prob_map is not None:\n",
    "    # 轻度平滑，降低噪声\n",
    "    prob_blur = cv2.GaussianBlur(prob_map, (5, 5), 0)\n",
    "\n",
    "    # 自适应Canny阈值（基于中位数）\n",
    "    v = np.median(prob_blur)\n",
    "    lower = int(max(0, 0.66 * v))\n",
    "    upper = int(min(255, 1.33 * v))\n",
    "\n",
    "    text_edges = cv2.Canny(prob_blur, lower, upper)\n",
    "\n",
    "    # 可选：稍微膨胀让边缘更清晰\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    text_edges = cv2.dilate(text_edges, kernel, iterations=1)\n",
    "\n",
    "    # 叠加到原始RGB图像上（绿色）\n",
    "    overlay_with_text_edges = img_rgb.copy()\n",
    "    overlay_with_text_edges[text_edges > 0] = [0, 255, 0]\n",
    "\n",
    "    # 可视化：概率图、边缘、叠加结果\n",
    "    plt.figure(figsize=(16, 5), dpi=300)\n",
    "    plt.subplot(131); plt.imshow(prob_map, cmap='gray'); plt.title('文字概率图'); plt.axis('off')\n",
    "    plt.subplot(132); plt.imshow(text_edges, cmap='gray'); plt.title('概率边缘'); plt.axis('off')\n",
    "    plt.subplot(133); plt.imshow(overlay_with_text_edges); plt.title('边缘叠加原图(绿色)'); plt.axis('off')\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print('未能生成概率图，跳过边缘叠加。')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c94c9c",
   "metadata": {},
   "source": [
    "### 将多通道融合的边缘图或者60%阈值图减去概率图消除文字的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586edf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将文字概率图做二值化\n",
    "if 'prob_map' not in globals() or prob_map is None:\n",
    "    print('未找到概率图 prob_map，跳过本单元。')\n",
    "else:\n",
    "    # 1) 概率图二值化（Otsu）得到文字掩膜\n",
    "    _, text_mask = cv2.threshold(prob_map, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # 形态学闭运算，填补小孔洞\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    # 2) 在融合的梯度图中将文字区域置零，得到“去文字”的融合多通道图\n",
    "    fused_gradient_no_text = np.array(fused_gradient, dtype=np.float32).copy()\n",
    "    fused_gradient_no_text[text_mask > 0] = 0.0\n",
    "\n",
    "    # 3) 按照60分位重新生成新的阈值图（基于去文字后的融合图）\n",
    "    p = 60\n",
    "    thr = np.percentile(fused_gradient_no_text, p)\n",
    "    binary_60_no_text = (fused_gradient_no_text > thr).astype(np.uint8) * 255\n",
    "    # 与之前流程保持一致：平滑后再次按60分位阈值\n",
    "    tmp = cv2.GaussianBlur(binary_60_no_text.astype(np.float32), (5, 5), 0)\n",
    "    thr2 = np.percentile(tmp, p)\n",
    "    binary_60_no_text = ((tmp > thr2).astype(np.uint8) * 255)\n",
    "\n",
    "    # 4) 将之前的60%阈值图与原始文字概率图作差，得到“消除文字之后的非阈值图”\n",
    "    if binary_55.shape != prob_map.shape:\n",
    "        prob_map_resized = cv2.resize(prob_map, (binary_55.shape[1], binary_55.shape[0]))\n",
    "    else:\n",
    "        prob_map_resized = prob_map\n",
    "    non_threshold_removed = cv2.subtract(binary_55, prob_map_resized)\n",
    "\n",
    "    # 5) 可视化结果\n",
    "    plt.figure(figsize=(20, 12), dpi=300)\n",
    "    plt.subplot(2, 4, 1); plt.imshow(prob_map, cmap='gray'); plt.title('原始文字概率图'); plt.axis('off')\n",
    "    plt.subplot(2, 4, 2); plt.imshow(text_mask, cmap='gray'); plt.title('文字概率二值掩膜'); plt.axis('off')\n",
    "    plt.subplot(2, 4, 3); plt.imshow(fused_gradient, cmap='hot'); plt.title('原始多通道融合图'); plt.axis('off')\n",
    "    plt.subplot(2, 4, 4); plt.imshow(fused_gradient_no_text, cmap='hot'); plt.title('去文字后的融合图'); plt.axis('off')\n",
    "    plt.subplot(2, 4, 5); plt.imshow(binary_55, cmap='gray'); plt.title('原60%阈值图'); plt.axis('off')\n",
    "    plt.subplot(2, 4, 6); plt.imshow(binary_60_no_text, cmap='gray'); plt.title('去文字后60%阈值图'); plt.axis('off')\n",
    "    plt.subplot(2, 4, 7); plt.imshow(non_threshold_removed, cmap='gray'); plt.title('原60%阈值图 - 概率图'); plt.axis('off')\n",
    "    # 第8幅：叠加文字掩膜可视化（可选）\n",
    "    mask_overlay = img_rgb.copy()\n",
    "    mask_overlay[text_mask > 0] = [255, 0, 255]\n",
    "    plt.subplot(2, 4, 8); plt.imshow(mask_overlay); plt.title('文字掩膜叠加原图'); plt.axis('off')\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a299423",
   "metadata": {},
   "source": [
    "# 第4步：基于形态学的网格线和交叉点检测（最终版本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8bfb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取投影的上边缘数据\n",
    "def extract_top_edge(projection_data, std_multiplier=2) -> tuple[np.ndarray, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    提取投影数据的上边缘（顶部）数据点\n",
    "\n",
    "    Args:\n",
    "        projection_data: 一维投影数据数组\n",
    "        std_multiplier: 标准差倍数，用于确定阈值\n",
    "\n",
    "    Returns:\n",
    "        top_edge_data: 超过阈值的数据点\n",
    "        threshold: 使用的阈值\n",
    "        indices: 超过阈值的数据点索引\n",
    "    \"\"\"\n",
    "    # 计算均值和标准差\n",
    "    mean = np.mean(projection_data)\n",
    "    std = np.std(projection_data)\n",
    "\n",
    "    # 定义阈值（均值 + n倍标准差）\n",
    "    # threshold = mean + std_multiplier * std\n",
    "\n",
    "    # 高分位点为阈值\n",
    "    threshold = np.quantile(projection_data, 0.95)\n",
    "\n",
    "    # 找到超过阈值的索引\n",
    "    indices = np.where(projection_data >= threshold)[0]\n",
    "\n",
    "    # 提取顶部数据\n",
    "    top_edge_data = projection_data[indices]\n",
    "\n",
    "    print(f\"投影数据统计: 均值={mean:.2f}, 标准差={std:.2f}\")\n",
    "    print(f\"阈值 (均值+{std_multiplier}σ): {threshold:.2f}\")\n",
    "    print(f\"提取到 {len(top_edge_data)} 个顶部数据点\")\n",
    "\n",
    "    return top_edge_data, threshold, indices\n",
    "def extract_grid_lines_morphology(binary_img, min_line_length=15,max_line_length=400, iterations=2):\n",
    "    \"\"\"\n",
    "    使用形态学的自适应网格操作提取水平线和垂直线\n",
    "    \"\"\"\n",
    "    print(f\"输入图像尺寸: {binary_img.shape}\")\n",
    "\n",
    "    # 初步检测以估算网格密度\n",
    "    initial_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))\n",
    "    temp_horizontal = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, initial_kernel, iterations=2)\n",
    "    # 投影每一行的白色像素（检测到的水平线像素）的总数\n",
    "    temp_projection = np.sum(temp_horizontal, axis=1)\n",
    "\n",
    "    from scipy.signal import find_peaks\n",
    "    # 找到所有峰值\n",
    "    temp_peaks, properties = find_peaks(temp_projection, height=np.max(temp_projection) * 0.1, distance=5)\n",
    "    # 获取上边缘峰值数据\n",
    "    filtered_indices = extract_top_edge(properties['peak_heights'],1)[2]\n",
    "    # mean_peak_height = np.mean(properties['peak_heights'])\n",
    "    # # 过滤掉低于平均值10%的峰值\n",
    "    # filtered_indices = np.where(properties['peak_heights'] >= mean_peak_height * 0.90)[0]\n",
    "    temp_peaks = temp_peaks[filtered_indices]\n",
    "    # 计算最大的峰值和最小的峰值的差，获得网格的总长度\n",
    "    if len(temp_peaks) > 0:\n",
    "        grid_length = np.max(temp_peaks) - np.min(temp_peaks)\n",
    "    else:\n",
    "        grid_length = 0\n",
    "    print(f\"网格线总跨度: {grid_length} 像素\")\n",
    "\n",
    "    # 计算网格密度并自适应调整线段长度\n",
    "    density = len(temp_peaks) / grid_length if len(temp_peaks) > 0 else 0.01\n",
    "    da = grid_length / len(temp_peaks)\n",
    "    adaptive_line_length = max(min_line_length, min(max_line_length, int(0.01/density * 100)))\n",
    "\n",
    "    print(f\"检测到网格密度: {density:.4f} 线/像素\")\n",
    "    print(f\"自适应线段长度: {adaptive_line_length} 像素\")\n",
    "\n",
    "    # 创建结构元素\n",
    "    # 水平线检测核 - 长水平线，窄垂直线\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (adaptive_line_length, 1))\n",
    "    # 垂直线检测核 - 窄水平线，长垂直线\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, adaptive_line_length))\n",
    "\n",
    "    # 形态学开运算提取线条\n",
    "    horizontal_lines = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN,\n",
    "                                      horizontal_kernel, iterations=iterations)\n",
    "    vertical_lines = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN,\n",
    "                                    vertical_kernel, iterations=iterations)\n",
    "\n",
    "    print(f\"提取的水平线像素数: {np.sum(horizontal_lines > 0)}\")\n",
    "    print(f\"提取的垂直线像素数: {np.sum(vertical_lines > 0)}\")\n",
    "\n",
    "    return horizontal_lines, vertical_lines\n",
    "\n",
    "def find_line_positions(line_mask, direction='horizontal'):\n",
    "    \"\"\"\n",
    "    从线条掩码中提取线条的精确位置\n",
    "    \"\"\"\n",
    "    if direction == 'horizontal':\n",
    "        # 水平线：在y方向上投影\n",
    "        projection = np.sum(line_mask, axis=1)\n",
    "    else:\n",
    "        # 垂直线：在x方向上投影\n",
    "        projection = np.sum(line_mask, axis=0)\n",
    "\n",
    "    # 找到投影的峰值位置\n",
    "    from scipy.signal import find_peaks\n",
    "\n",
    "    # 设置峰值检测参数\n",
    "    height_threshold = np.max(projection) * 0.1  # 10%的最大值作为阈值\n",
    "    min_distance = 5  # 最小间距\n",
    "\n",
    "    peaks, properties = find_peaks(projection, height=height_threshold, distance=min_distance)\n",
    "    if len(peaks) > 0:\n",
    "        mean_peak_height = np.mean(properties['peak_heights'])\n",
    "        filtered_indices = np.where(properties['peak_heights'] >= mean_peak_height * 0.90)[0]\n",
    "        peaks = peaks[filtered_indices]\n",
    "\n",
    "    return peaks, projection\n",
    "\n",
    "def detect_grid_intersections_morphology(horizontal_lines, vertical_lines):\n",
    "    \"\"\"\n",
    "    检测网格交叉点\n",
    "    \"\"\"\n",
    "    # 找到交叉点：水平线和垂直线的交集\n",
    "    intersections_mask = cv2.bitwise_and(horizontal_lines, vertical_lines)\n",
    "\n",
    "    # 使用连通组件找到交叉点位置\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "        intersections_mask, connectivity=8)\n",
    "\n",
    "    # 过滤掉面积太小的组件\n",
    "    min_area = 2  # 最小面积阈值\n",
    "    valid_intersections = []\n",
    "\n",
    "    for i in range(1, num_labels):  # 跳过背景标签0\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area >= min_area:\n",
    "            cx, cy = centroids[i]\n",
    "            valid_intersections.append((cx, cy))\n",
    "\n",
    "    print(f\"检测到 {len(valid_intersections)} 个网格交叉点\")\n",
    "\n",
    "    return np.array(valid_intersections), intersections_mask\n",
    "\n",
    "# 执行形态学网格检测\n",
    "print(\"=== 开始形态学网格检测 ===\")\n",
    "\n",
    "# 1. 提取水平线和垂直线\n",
    "horizontal_lines, vertical_lines = extract_grid_lines_morphology(\n",
    "    binary_55, min_line_length=5,max_line_length=400, iterations=2)\n",
    "\n",
    "# 2. 获取线条位置\n",
    "horizontal_positions, h_projection = find_line_positions(horizontal_lines, 'horizontal')\n",
    "vertical_positions, v_projection = find_line_positions(vertical_lines, 'vertical')\n",
    "\n",
    "print(f\"检测到 {len(horizontal_positions)} 条水平线\")\n",
    "print(f\"检测到 {len(vertical_positions)} 条垂直线\")\n",
    "\n",
    "# 3. 检测交叉点\n",
    "grid_intersections, intersection_mask = detect_grid_intersections_morphology(\n",
    "    horizontal_lines, vertical_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b90e4f",
   "metadata": {},
   "source": [
    "# 第5步：形态学检测结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 16), dpi=300)\n",
    "\n",
    "# 1. 原始图像\n",
    "plt.subplot(3, 4, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('原始拼豆图纸')\n",
    "plt.axis('off')\n",
    "\n",
    "# 2. 60%阈值二值图\n",
    "plt.subplot(3, 4, 2)\n",
    "plt.imshow(binary_55, cmap='gray')\n",
    "plt.title('60%阈值二值图')\n",
    "plt.axis('off')\n",
    "\n",
    "# 3. 提取的水平线\n",
    "plt.subplot(3, 4, 3)\n",
    "plt.imshow(horizontal_lines, cmap='gray')\n",
    "plt.title(f'水平线提取\\n{len(horizontal_positions)}条线')\n",
    "plt.axis('off')\n",
    "\n",
    "# 4. 提取的垂直线\n",
    "plt.subplot(3, 4, 4)\n",
    "plt.imshow(vertical_lines, cmap='gray')\n",
    "plt.title(f'垂直线提取\\n{len(vertical_positions)}条线')\n",
    "plt.axis('off')\n",
    "\n",
    "# 5. 水平线投影分析\n",
    "plt.subplot(3, 4, 5)\n",
    "plt.plot(h_projection, range(len(h_projection)), color='blue')\n",
    "plt.scatter(h_projection[horizontal_positions], horizontal_positions,\n",
    "           color='red', s=50, zorder=5)\n",
    "plt.title('水平线投影')\n",
    "plt.xlabel('投影强度')\n",
    "plt.ylabel('Y坐标')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. 垂直线投影分析\n",
    "plt.subplot(3, 4, 6)\n",
    "plt.plot(v_projection, color='green')\n",
    "plt.scatter(vertical_positions, v_projection[vertical_positions],\n",
    "           color='red', s=50, zorder=5)\n",
    "plt.title('垂直线投影')\n",
    "plt.xlabel('X坐标')\n",
    "plt.ylabel('投影强度')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. 交叉点掩码\n",
    "plt.subplot(3, 4, 7)\n",
    "plt.imshow(intersection_mask, cmap='gray')\n",
    "plt.title('交叉点掩码')\n",
    "plt.axis('off')\n",
    "\n",
    "# 8. 合并的线条图\n",
    "plt.subplot(3, 4, 8)\n",
    "combined_lines = cv2.bitwise_or(horizontal_lines, vertical_lines)\n",
    "plt.imshow(combined_lines, cmap='gray')\n",
    "plt.title('合并线条')\n",
    "plt.axis('off')\n",
    "\n",
    "# 9. 线条叠加在原图上\n",
    "plt.subplot(3, 4, 9)\n",
    "lines_overlay = img_rgb.copy()\n",
    "# 水平线 - 绿色\n",
    "lines_overlay[horizontal_lines > 0] = [0, 255, 0]\n",
    "# 垂直线 - 红色\n",
    "lines_overlay[vertical_lines > 0] = [255, 0, 0]\n",
    "# 交叉点 - 黄色\n",
    "lines_overlay[intersection_mask > 0] = [255, 255, 0]\n",
    "plt.imshow(lines_overlay)\n",
    "plt.title('线条叠加原图\\n红=垂直,绿=水平,黄=交叉')\n",
    "plt.axis('off')\n",
    "\n",
    "# 10. 交叉点标记\n",
    "plt.subplot(3, 4, 10)\n",
    "intersection_result = img_rgb.copy()\n",
    "for i, (x, y) in enumerate(grid_intersections):\n",
    "    cv2.circle(intersection_result, (int(x), int(y)), 4, (255, 0, 0), -1)\n",
    "    # 每50个点标注序号\n",
    "    if i % 50 == 0:\n",
    "        cv2.putText(intersection_result, str(i), (int(x)+5, int(y)-5),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "plt.imshow(intersection_result)\n",
    "plt.title(f'网格交叉点\\n共{len(grid_intersections)}个')\n",
    "plt.axis('off')\n",
    "\n",
    "# 11. 网格间距分析\n",
    "plt.subplot(3, 4, 11)\n",
    "if len(grid_intersections) > 4:\n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    # 计算最近邻距离\n",
    "    distances = cdist(grid_intersections, grid_intersections)\n",
    "    np.fill_diagonal(distances, np.inf)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "\n",
    "    plt.hist(min_distances, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "\n",
    "    # 统计信息\n",
    "    median_spacing = np.median(min_distances)\n",
    "    mean_spacing = np.mean(min_distances)\n",
    "    std_spacing = np.std(min_distances)\n",
    "\n",
    "    plt.axvline(median_spacing, color='red', linestyle='--',\n",
    "               label=f'中位数: {median_spacing:.1f}')\n",
    "    plt.axvline(mean_spacing, color='green', linestyle='--',\n",
    "               label=f'平均值: {mean_spacing:.1f}')\n",
    "\n",
    "    plt.title(f'网格间距分布\\n标准差: {std_spacing:.1f}')\n",
    "    plt.xlabel('距离(像素)')\n",
    "    plt.ylabel('频次')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, '交点数据不足', ha='center', va='center',\n",
    "             transform=plt.gca().transAxes)\n",
    "    plt.title('网格间距分析')\n",
    "\n",
    "# 12. 交点分布图\n",
    "plt.subplot(3, 4, 12)\n",
    "if len(grid_intersections) > 0:\n",
    "    plt.scatter(grid_intersections[:, 0], grid_intersections[:, 1],\n",
    "               alpha=0.7, s=20, c='red')\n",
    "    plt.title(f'交点分布图\\n{len(grid_intersections)}个交点')\n",
    "    plt.xlabel('X坐标')\n",
    "    plt.ylabel('Y坐标')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # 显示网格的大概范围\n",
    "    x_min, x_max = np.min(grid_intersections[:, 0]), np.max(grid_intersections[:, 0])\n",
    "    y_min, y_max = np.min(grid_intersections[:, 1]), np.max(grid_intersections[:, 1])\n",
    "\n",
    "    plt.text(0.02, 0.98, f'X范围: {x_min:.0f}-{x_max:.0f}\\nY范围: {y_min:.0f}-{y_max:.0f}',\n",
    "             transform=plt.gca().transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
